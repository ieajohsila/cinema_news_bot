import json
import os
import logging
from datetime import datetime, timedelta
from pathlib import Path

# Logger
logger = logging.getLogger(__name__)

# ================= BASE PATH =================
BASE = Path("data")
BASE.mkdir(exist_ok=True)

# ================= FILES =================
FILES = {
    "settings": BASE / "settings.json",
    "sources": BASE / "sources.json",
    "sent": BASE / "sent.json",
    "topics": BASE / "topics.json",
    "news": BASE / "collected_news.json",
}

# ================= HELPERS =================
def _ensure_file(path: Path, default):
    if not path.exists():
        with open(path, "w", encoding="utf-8") as f:
            json.dump(default, f, ensure_ascii=False, indent=2)

def _load_file(path: Path, default):
    _ensure_file(path, default)
    with open(path, encoding="utf-8") as f:
        return json.load(f)

def _save_file(path: Path, data):
    with open(path, "w", encoding="utf-8") as f:
        json.dump(data, f, ensure_ascii=False, indent=2)

# ================= SETTINGS =================
def get_setting(key, default=None):
    """
    ğŸ”§ FIX: Ø§ÙˆÙ„ Ø§Ø² ENV Ø¨Ø®ÙˆØ§Ù†ØŒ Ø¨Ø¹Ø¯ Ø§Ø² ÙØ§ÛŒÙ„
    """
    # 1. Ú†Ú© Ú©Ø±Ø¯Ù† Environment Variable
    env_value = os.getenv(key)
    if env_value is not None:
        return env_value
    
    # 2. Ú†Ú© Ú©Ø±Ø¯Ù† ÙØ§ÛŒÙ„ ØªÙ†Ø¸ÛŒÙ…Ø§Øª
    data = _load_file(FILES["settings"], {})
    return data.get(key, default)

def set_setting(key, value):
    data = _load_file(FILES["settings"], {})
    data[key] = value
    _save_file(FILES["settings"], data)

# ================= SOURCES =================
def get_sources():
    return _load_file(FILES["sources"], {"rss": [], "scrape": []})

def get_rss_sources():
    return get_sources().get("rss", [])

def get_scrape_sources():
    return get_sources().get("scrape", [])

def add_rss_source(url):
    data = get_sources()
    if url not in data["rss"]:
        data["rss"].append(url)
        _save_file(FILES["sources"], data)

def add_scrape_source(url):
    data = get_sources()
    if url not in data["scrape"]:
        data["scrape"].append(url)
        _save_file(FILES["sources"], data)

def remove_rss_source(url):
    data = get_sources()
    if url in data["rss"]:
        data["rss"].remove(url)
        _save_file(FILES["sources"], data)

def remove_scrape_source(url):
    data = get_sources()
    if url in data["scrape"]:
        data["scrape"].remove(url)
        _save_file(FILES["sources"], data)

# ================= SENT (ØªÚ©Ø±Ø§Ø±ÛŒ Ù†Ø¨ÙˆØ¯Ù† Ø§Ø®Ø¨Ø§Ø±) =================
def is_sent(uid):
    """Ø¨Ø±Ø±Ø³ÛŒ Ø§ÛŒÙ†Ú©Ù‡ Ø®Ø¨Ø± Ù‚Ø¨Ù„Ø§Ù‹ Ø§Ø±Ø³Ø§Ù„ Ø´Ø¯Ù‡ ÛŒØ§ Ù†Ù‡"""
    try:
        data = _load_file(FILES["sent"], [])
        # ğŸ”§ FIX: ØªØ¨Ø¯ÛŒÙ„ Ø¨Ù‡ string Ø¨Ø±Ø§ÛŒ Ù…Ù‚Ø§ÛŒØ³Ù‡
        return str(uid) in [str(x) for x in data]
    except Exception as e:
        logger.error(f"Ø®Ø·Ø§ Ø¯Ø± is_sent: {e}")
        return False

def mark_sent(uid):
    """Ø¹Ù„Ø§Ù…Øªâ€ŒÚ¯Ø°Ø§Ø±ÛŒ Ø®Ø¨Ø± Ø¨Ù‡ Ø¹Ù†ÙˆØ§Ù† Ø§Ø±Ø³Ø§Ù„ Ø´Ø¯Ù‡"""
    try:
        data = _load_file(FILES["sent"], [])
        uid_str = str(uid)
        
        # ğŸ”§ FIX: Ú†Ú© Ú©Ø±Ø¯Ù† ØªÚ©Ø±Ø§Ø±ÛŒ Ù†Ø¨ÙˆØ¯Ù†
        if uid_str not in [str(x) for x in data]:
            data.append(uid_str)
            
            # ğŸ”§ FIX: Ù†Ú¯Ù‡ Ø¯Ø§Ø´ØªÙ† ÙÙ‚Ø· 2000 Ø¢ÛŒØªÙ… Ø¢Ø®Ø±
            if len(data) > 2000:
                data = data[-2000:]
            
            _save_file(FILES["sent"], data)
            return True
        return False
    except Exception as e:
        logger.error(f"Ø®Ø·Ø§ Ø¯Ø± mark_sent: {e}")
        return False

# ================= COLLECTED NEWS =================
def save_collected_news(news_list):
    _save_file(FILES["news"], news_list)

def get_collected_news(limit=None):
    news = _load_file(FILES["news"], [])
    return news[:limit] if limit else news

# ================= TOPICS / TRENDS =================
def save_topic(topic, url, source):
    """Ø°Ø®ÛŒØ±Ù‡ ÛŒÚ© ØªØ§Ù¾ÛŒÚ© Ø¨Ø±Ø§ÛŒ ØªØ­Ù„ÛŒÙ„ ØªØ±Ù†Ø¯"""
    data = _load_file(FILES["topics"], [])
    today = datetime.utcnow().date().isoformat()
    data.append({
        "topic": topic,
        "url": url,
        "source": source,
        "date": today
    })
    # Ù†Ú¯Ù‡ Ø¯Ø§Ø´ØªÙ† ÙÙ‚Ø· 30 Ø±ÙˆØ² Ø§Ø®ÛŒØ±
    cutoff = (datetime.utcnow().date() - timedelta(days=30)).isoformat()
    data = [item for item in data if item.get("date", "") >= cutoff]
    _save_file(FILES["topics"], data)

def daily_trends(min_sources=3):
    """Ù¾ÛŒØ¯Ø§ Ú©Ø±Ø¯Ù† ØªØ±Ù†Ø¯Ù‡Ø§ÛŒ Ø±ÙˆØ²Ø§Ù†Ù‡"""
    data = _load_file(FILES["topics"], [])
    today = datetime.utcnow().date().isoformat()
    count = {}

    for item in data:
        if item.get("date") == today:
            topic = item.get("topic", "")
            source = item.get("source", "")
            if topic:
                if topic not in count:
                    count[topic] = set()
                count[topic].add(source)

    # ÙÛŒÙ„ØªØ± ØªØ±Ù†Ø¯Ù‡Ø§ Ø¨Ø§ Ø­Ø¯Ø§Ù‚Ù„ ØªØ¹Ø¯Ø§Ø¯ Ù…Ù†Ø¨Ø¹
    trends = [topic for topic, sources in count.items() if len(sources) >= min_sources]
    return trendsimport json
import os
import logging
from datetime import datetime, timedelta
from pathlib import Path

# Logger
logger = logging.getLogger(__name__)

# ================= BASE PATH =================
BASE = Path("data")
BASE.mkdir(exist_ok=True)

# ================= FILES =================
FILES = {
    "settings": BASE / "settings.json",
    "sources": BASE / "sources.json",
    "sent": BASE / "sent.json",
    "topics": BASE / "topics.json",
    "news": BASE / "collected_news.json",
}

# ================= HELPERS =================
def _ensure_file(path: Path, default):
    if not path.exists():
        with open(path, "w", encoding="utf-8") as f:
            json.dump(default, f, ensure_ascii=False, indent=2)

def _load_file(path: Path, default):
    _ensure_file(path, default)
    with open(path, encoding="utf-8") as f:
        return json.load(f)

def _save_file(path: Path, data):
    with open(path, "w", encoding="utf-8") as f:
        json.dump(data, f, ensure_ascii=False, indent=2)

# ================= SETTINGS =================
def get_setting(key, default=None):
    """
    ğŸ”§ FIX: Ø§ÙˆÙ„ Ø§Ø² ENV Ø¨Ø®ÙˆØ§Ù†ØŒ Ø¨Ø¹Ø¯ Ø§Ø² ÙØ§ÛŒÙ„
    """
    # 1. Ú†Ú© Ú©Ø±Ø¯Ù† Environment Variable
    env_value = os.getenv(key)
    if env_value is not None:
        return env_value
    
    # 2. Ú†Ú© Ú©Ø±Ø¯Ù† ÙØ§ÛŒÙ„ ØªÙ†Ø¸ÛŒÙ…Ø§Øª
    data = _load_file(FILES["settings"], {})
    return data.get(key, default)

def set_setting(key, value):
    data = _load_file(FILES["settings"], {})
    data[key] = value
    _save_file(FILES["settings"], data)

# ================= SOURCES =================
def get_sources():
    return _load_file(FILES["sources"], {"rss": [], "scrape": []})

def get_rss_sources():
    return get_sources().get("rss", [])

def get_scrape_sources():
    return get_sources().get("scrape", [])

def add_rss_source(url):
    data = get_sources()
    if url not in data["rss"]:
        data["rss"].append(url)
        _save_file(FILES["sources"], data)

def add_scrape_source(url):
    data = get_sources()
    if url not in data["scrape"]:
        data["scrape"].append(url)
        _save_file(FILES["sources"], data)

def remove_rss_source(url):
    data = get_sources()
    if url in data["rss"]:
        data["rss"].remove(url)
        _save_file(FILES["sources"], data)

def remove_scrape_source(url):
    data = get_sources()
    if url in data["scrape"]:
        data["scrape"].remove(url)
        _save_file(FILES["sources"], data)

# ================= SENT (ØªÚ©Ø±Ø§Ø±ÛŒ Ù†Ø¨ÙˆØ¯Ù† Ø§Ø®Ø¨Ø§Ø±) =================
def is_sent(uid):
    """Ø¨Ø±Ø±Ø³ÛŒ Ø§ÛŒÙ†Ú©Ù‡ Ø®Ø¨Ø± Ù‚Ø¨Ù„Ø§Ù‹ Ø§Ø±Ø³Ø§Ù„ Ø´Ø¯Ù‡ ÛŒØ§ Ù†Ù‡"""
    try:
        data = _load_file(FILES["sent"], [])
        # ğŸ”§ FIX: ØªØ¨Ø¯ÛŒÙ„ Ø¨Ù‡ string Ø¨Ø±Ø§ÛŒ Ù…Ù‚Ø§ÛŒØ³Ù‡
        return str(uid) in [str(x) for x in data]
    except Exception as e:
        logger.error(f"Ø®Ø·Ø§ Ø¯Ø± is_sent: {e}")
        return False

def mark_sent(uid):
    """Ø¹Ù„Ø§Ù…Øªâ€ŒÚ¯Ø°Ø§Ø±ÛŒ Ø®Ø¨Ø± Ø¨Ù‡ Ø¹Ù†ÙˆØ§Ù† Ø§Ø±Ø³Ø§Ù„ Ø´Ø¯Ù‡"""
    try:
        data = _load_file(FILES["sent"], [])
        uid_str = str(uid)
        
        # ğŸ”§ FIX: Ú†Ú© Ú©Ø±Ø¯Ù† ØªÚ©Ø±Ø§Ø±ÛŒ Ù†Ø¨ÙˆØ¯Ù†
        if uid_str not in [str(x) for x in data]:
            data.append(uid_str)
            
            # ğŸ”§ FIX: Ù†Ú¯Ù‡ Ø¯Ø§Ø´ØªÙ† ÙÙ‚Ø· 2000 Ø¢ÛŒØªÙ… Ø¢Ø®Ø±
            if len(data) > 2000:
                data = data[-2000:]
            
            _save_file(FILES["sent"], data)
            return True
        return False
    except Exception as e:
        logger.error(f"Ø®Ø·Ø§ Ø¯Ø± mark_sent: {e}")
        return False

# ================= COLLECTED NEWS =================
def save_collected_news(news_list):
    _save_file(FILES["news"], news_list)

def get_collected_news(limit=None):
    news = _load_file(FILES["news"], [])
    return news[:limit] if limit else news

# ================= TOPICS / TRENDS =================
def save_topic(topic, url, source):
    """Ø°Ø®ÛŒØ±Ù‡ ÛŒÚ© ØªØ§Ù¾ÛŒÚ© Ø¨Ø±Ø§ÛŒ ØªØ­Ù„ÛŒÙ„ ØªØ±Ù†Ø¯"""
    data = _load_file(FILES["topics"], [])
    today = datetime.utcnow().date().isoformat()
    data.append({
        "topic": topic,
        "url": url,
        "source": source,
        "date": today
    })
    # Ù†Ú¯Ù‡ Ø¯Ø§Ø´ØªÙ† ÙÙ‚Ø· 30 Ø±ÙˆØ² Ø§Ø®ÛŒØ±
    cutoff = (datetime.utcnow().date() - timedelta(days=30)).isoformat()
    data = [item for item in data if item.get("date", "") >= cutoff]
    _save_file(FILES["topics"], data)

def daily_trends(min_sources=3):
    """Ù¾ÛŒØ¯Ø§ Ú©Ø±Ø¯Ù† ØªØ±Ù†Ø¯Ù‡Ø§ÛŒ Ø±ÙˆØ²Ø§Ù†Ù‡"""
    data = _load_file(FILES["topics"], [])
    today = datetime.utcnow().date().isoformat()
    count = {}

    for item in data:
        if item.get("date") == today:
            topic = item.get("topic", "")
            source = item.get("source", "")
            if topic:
                if topic not in count:
                    count[topic] = set()
                count[topic].add(source)

    # ÙÛŒÙ„ØªØ± ØªØ±Ù†Ø¯Ù‡Ø§ Ø¨Ø§ Ø­Ø¯Ø§Ù‚Ù„ ØªØ¹Ø¯Ø§Ø¯ Ù…Ù†Ø¨Ø¹
    trends = [topic for topic, sources in count.items() if len(sources) >= min_sources]
    return trends
