"""
Ù…Ø¯ÛŒØ±ÛŒØª Ø¯ÛŒØªØ§Ø¨ÛŒØ³ - Ù†Ø³Ø®Ù‡ Ú©Ø§Ù…Ù„ Ùˆ Ø¨Ø¯ÙˆÙ† Ø¨Ø§Ú¯
Ù‡Ù…Ù‡ ØªÙˆØ§Ø¨Ø¹ Ù…ÙˆØ±Ø¯ Ù†ÛŒØ§Ø² ØªØ¹Ø±ÛŒÙ Ø´Ø¯Ù‡â€ŒØ§Ù†Ø¯
"""

import json
import os
from datetime import datetime, timedelta
from pathlib import Path

BASE = "data"
os.makedirs(BASE, exist_ok=True)

FILES = {
    "settings": f"{BASE}/settings.json",
    "sources": f"{BASE}/sources.json",
    "sent": f"{BASE}/sent.json",
    "topics": f"{BASE}/topics.json",
    "collected_news": f"{BASE}/collected_news.json"
}

def _load(name, default):
    """Ø¨Ø§Ø±Ú¯Ø°Ø§Ø±ÛŒ Ø§Ù…Ù† ÙØ§ÛŒÙ„ JSON"""
    try:
        if not os.path.exists(FILES[name]):
            with open(FILES[name], "w", encoding="utf-8") as f:
                json.dump(default, f, ensure_ascii=False, indent=2)
            return default
        
        with open(FILES[name], encoding="utf-8") as f:
            content = f.read().strip()
            
            if not content:
                with open(FILES[name], "w", encoding="utf-8") as f:
                    json.dump(default, f, ensure_ascii=False, indent=2)
                return default
            
            data = json.loads(content)
            return data
    except Exception as e:
        print(f"âš ï¸ Ø®Ø·Ø§ Ø¯Ø± Ø¨Ø§Ø±Ú¯Ø°Ø§Ø±ÛŒ {name}: {e}")
        return default

def _save(name, data):
    """Ø°Ø®ÛŒØ±Ù‡ Ø§Ù…Ù† ÙØ§ÛŒÙ„ JSON"""
    try:
        with open(FILES[name], "w", encoding="utf-8") as f:
            json.dump(data, f, ensure_ascii=False, indent=2)
    except Exception as e:
        print(f"âŒ Ø®Ø·Ø§ Ø¯Ø± Ø°Ø®ÛŒØ±Ù‡ {name}: {e}")

# ============ SETTINGS ============
def get_setting(key, default=None):
    """Ø¯Ø±ÛŒØ§ÙØª ÛŒÚ© ØªÙ†Ø¸ÛŒÙ…"""
    s = _load("settings", {})
    return s.get(key, default)

def set_setting(key, value):
    """Ø°Ø®ÛŒØ±Ù‡ ÛŒÚ© ØªÙ†Ø¸ÛŒÙ…"""
    s = _load("settings", {})
    s[key] = value
    _save("settings", s)

# ============ SOURCES ============
def get_sources():
    """Ø¨Ø±Ú¯Ø±Ø¯Ø§Ù†Ø¯Ù† Ù‡Ù…Ù‡ Ù…Ù†Ø§Ø¨Ø¹"""
    return _load("sources", {"rss": [], "scrape": []})

def get_rss_sources():
    """Ø¯Ø±ÛŒØ§ÙØª Ù…Ù†Ø§Ø¨Ø¹ RSS"""
    data = get_sources()
    return data.get("rss", [])

def get_scrape_sources():
    """Ø¯Ø±ÛŒØ§ÙØª Ù…Ù†Ø§Ø¨Ø¹ Scrape"""
    data = get_sources()
    return data.get("scrape", [])

def add_rss_source(url):
    """Ø§ÙØ²ÙˆØ¯Ù† Ù…Ù†Ø¨Ø¹ RSS"""
    data = get_sources()
    if "rss" not in data:
        data["rss"] = []
    if url not in data["rss"]:
        data["rss"].append(url)
        _save("sources", data)

def add_scrape_source(url):
    """Ø§ÙØ²ÙˆØ¯Ù† Ù…Ù†Ø¨Ø¹ Scrape"""
    data = get_sources()
    if "scrape" not in data:
        data["scrape"] = []
    if url not in data["scrape"]:
        data["scrape"].append(url)
        _save("sources", data)

def remove_rss_source(url):
    """Ø­Ø°Ù Ù…Ù†Ø¨Ø¹ RSS"""
    data = get_sources()
    if "rss" in data and url in data["rss"]:
        data["rss"].remove(url)
        _save("sources", data)

def remove_scrape_source(url):
    """Ø­Ø°Ù Ù…Ù†Ø¨Ø¹ Scrape"""
    data = get_sources()
    if "scrape" in data and url in data["scrape"]:
        data["scrape"].remove(url)
        _save("sources", data)

# ============ SENT ============
def is_sent(uid):
    """Ú†Ú© Ú©Ø±Ø¯Ù† Ø§Ø±Ø³Ø§Ù„ Ø´Ø¯Ù‡ Ø¨ÙˆØ¯Ù†"""
    sent_list = _load("sent", [])
    if not isinstance(sent_list, list):
        sent_list = []
    return uid in sent_list

def mark_sent(uid):
    """Ø¹Ù„Ø§Ù…Øªâ€ŒÚ¯Ø°Ø§Ø±ÛŒ Ø¨Ù‡ Ø¹Ù†ÙˆØ§Ù† Ø§Ø±Ø³Ø§Ù„ Ø´Ø¯Ù‡"""
    sent_list = _load("sent", [])
    if not isinstance(sent_list, list):
        sent_list = []
    if uid not in sent_list:
        sent_list.append(uid)
        _save("sent", sent_list)

def cleanup_old_sent(days=30):
    """Ù¾Ø§Ú©Ø³Ø§Ø²ÛŒ Ù„ÛŒØ³Øª sent (ÙØ¹Ù„Ø§Ù‹ ÙÙ‚Ø· Ù…Ø­Ø¯ÙˆØ¯ÛŒØª ØªØ¹Ø¯Ø§Ø¯)"""
    sent_list = _load("sent", [])
    if not isinstance(sent_list, list):
        return
    
    # Ù†Ú¯Ù‡â€ŒØ¯Ø§Ø´ØªÙ† ÙÙ‚Ø· 10000 Ø¢ÛŒØªÙ… Ø¢Ø®Ø±
    if len(sent_list) > 10000:
        sent_list = sent_list[-10000:]
        _save("sent", sent_list)

# ============ TOPICS ============
def save_topic(topic, link, source, date):
    """Ø°Ø®ÛŒØ±Ù‡ topic Ø¨Ø±Ø§ÛŒ ØªØ­Ù„ÛŒÙ„ ØªØ±Ù†Ø¯"""
    data = _load("topics", [])
    
    # Ø§Ø·Ù…ÛŒÙ†Ø§Ù† Ø§Ø² Ø§ÛŒÙ†Ú©Ù‡ Ù„ÛŒØ³Øª Ø§Ø³Øª
    if not isinstance(data, list):
        data = []
    
    data.append({
        "topic": topic,
        "link": link,
        "source": source,
        "date": date,
        "timestamp": datetime.now().isoformat()
    })
    
    _save("topics", data)

def daily_trends(date=None):
    """Ø¯Ø±ÛŒØ§ÙØª ØªØ±Ù†Ø¯Ù‡Ø§ÛŒ ÛŒÚ© Ø±ÙˆØ² Ø®Ø§Øµ"""
    if date is None:
        date = datetime.utcnow().date().isoformat()
    
    data = _load("topics", [])
    
    # Ø§Ø·Ù…ÛŒÙ†Ø§Ù† Ø§Ø² Ø§ÛŒÙ†Ú©Ù‡ Ù„ÛŒØ³Øª Ø§Ø³Øª
    if not isinstance(data, list):
        return []
    
    count = {}
    
    for item in data:
        if not isinstance(item, dict):
            continue
        
        if item.get("date") == date:
            topic = item.get("topic", "")
            source = item.get("source", "unknown")
            link = item.get("link", "")
            
            if not topic:
                continue
            
            if topic not in count:
                count[topic] = {"sources": set(), "links": []}
            
            count[topic]["sources"].add(source)
            count[topic]["links"].append(link)
    
    # ØªØ±Ù†Ø¯Ù‡Ø§: Ù…ÙˆØ¶ÙˆØ¹Ø§ØªÛŒ Ú©Ù‡ Ø§Ø² 2 Ù…Ù†Ø¨Ø¹ ÛŒØ§ Ø¨ÛŒØ´ØªØ± Ø¢Ù…Ø¯Ù‡â€ŒØ§Ù†Ø¯
    trends = []
    for topic, info in count.items():
        if len(info["sources"]) >= 2:
            trends.append({
                "topic": topic,
                "source_count": len(info["sources"]),
                "sources": list(info["sources"]),
                "links": info["links"][:3]
            })
    
    # Ù…Ø±ØªØ¨â€ŒØ³Ø§Ø²ÛŒ Ø¨Ø± Ø§Ø³Ø§Ø³ ØªØ¹Ø¯Ø§Ø¯ Ù…Ù†Ø§Ø¨Ø¹
    trends.sort(key=lambda x: x["source_count"], reverse=True)
    return trends

# ============ COLLECTED NEWS ============
def save_collected_news(news_list):
    """Ø°Ø®ÛŒØ±Ù‡ Ø§Ø®Ø¨Ø§Ø± Ø¬Ù…Ø¹â€ŒØ¢ÙˆØ±ÛŒ Ø´Ø¯Ù‡ Ø±ÙˆØ²Ø§Ù†Ù‡"""
    today = datetime.utcnow().date().isoformat()
    
    all_news = _load("collected_news", {})
    
    # Ø§Ø·Ù…ÛŒÙ†Ø§Ù† Ø§Ø² Ø§ÛŒÙ†Ú©Ù‡ dict Ø§Ø³Øª
    if not isinstance(all_news, dict):
        all_news = {}
    
    if today not in all_news:
        all_news[today] = []
    
    # Ø¯Ø±ÛŒØ§ÙØª Ù„ÛŒÙ†Ú©â€ŒÙ‡Ø§ÛŒ Ù…ÙˆØ¬ÙˆØ¯
    existing_links = {news.get("link") for news in all_news[today]}
    
    # Ø§Ø¶Ø§ÙÙ‡ Ú©Ø±Ø¯Ù† Ø§Ø®Ø¨Ø§Ø± Ø¬Ø¯ÛŒØ¯
    for news in news_list:
        link = news.get("link")
        if link and link not in existing_links:
            all_news[today].append(news)
            existing_links.add(link)
    
    # Ø­Ø°Ù Ø§Ø®Ø¨Ø§Ø± Ù‚Ø¯ÛŒÙ…ÛŒâ€ŒØªØ± Ø§Ø² 7 Ø±ÙˆØ²
    cutoff_date = (datetime.utcnow().date() - timedelta(days=7)).isoformat()
    all_news = {d: n for d, n in all_news.items() if d >= cutoff_date}
    
    _save("collected_news", all_news)

def get_collected_news(limit=None, date=None):
    """Ø®ÙˆØ§Ù†Ø¯Ù† Ø§Ø®Ø¨Ø§Ø± Ø¬Ù…Ø¹â€ŒØ¢ÙˆØ±ÛŒ Ø´Ø¯Ù‡"""
    all_news = _load("collected_news", {})
    
    if not isinstance(all_news, dict):
        return []
    
    if date is None:
        date = datetime.utcnow().date().isoformat()
    
    news = all_news.get(date, [])
    
    if not isinstance(news, list):
        return []
    
    if limit:
        return news[:limit]
    return news

def get_all_collected_news(days=7):
    """Ø¯Ø±ÛŒØ§ÙØª ØªÙ…Ø§Ù… Ø§Ø®Ø¨Ø§Ø± Ú†Ù†Ø¯ Ø±ÙˆØ² Ø§Ø®ÛŒØ±"""
    all_news = _load("collected_news", {})
    
    if not isinstance(all_news, dict):
        return []
    
    result = []
    for date in sorted(all_news.keys(), reverse=True)[:days]:
        news = all_news[date]
        if isinstance(news, list):
            result.extend(news)
    
    return result


# ============ ØªØ³Øª ============
if __name__ == "__main__":
    print("\n" + "="*60)
    print("ğŸ§ª ØªØ³Øª Ù…Ø§Ú˜ÙˆÙ„ database")
    print("="*60 + "\n")
    
    # ØªØ³Øª settings
    set_setting("test_key", "test_value")
    print(f"âœ… Settings: {get_setting('test_key')}")
    
    # ØªØ³Øª sources
    add_rss_source("https://test.com/feed")
    print(f"âœ… RSS Sources: {len(get_rss_sources())}")
    
    add_scrape_source("https://test.com/news")
    print(f"âœ… Scrape Sources: {len(get_scrape_sources())}")
    
    # ØªØ³Øª sent
    mark_sent("test_link_123")
    print(f"âœ… Is Sent: {is_sent('test_link_123')}")
    
    # ØªØ³Øª topics
    save_topic("Test Topic", "https://test.com", "test_source", "2025-01-01")
    trends = daily_trends("2025-01-01")
    print(f"âœ… Topics: {len(trends)} trends")
    
    # ØªØ³Øª collected_news
    save_collected_news([
        {"title": "Test News", "link": "https://test.com/1", "summary": "Test"}
    ])
    news = get_collected_news()
    print(f"âœ… Collected News: {len(news)} items")
    
    print("\n" + "="*60)
    print("âœ… Ù‡Ù…Ù‡ ØªØ³Øªâ€ŒÙ‡Ø§ Ù…ÙˆÙÙ‚!")
    print("="*60 + "\n")
