import json
import os
import logging
from datetime import datetime, timedelta
from pathlib import Path

logger = logging.getLogger(__name__)

# ================= BASE PATH =================
BASE = Path("data")
BASE.mkdir(exist_ok=True)

# ÙØ§ÛŒÙ„ Ø¬Ù…Ø¹â€ŒØ¢ÙˆØ±ÛŒ Ø§Ø®Ø¨Ø§Ø±
DB_FILE = BASE / "collected_news.json"

# ================= FILES =================
FILES = {
    "settings": BASE / "settings.json",
    "sources": BASE / "sources.json",
    "sent": BASE / "sent.json",
    "topics": BASE / "topics.json",
    "news": BASE / "collected_news.json",
}

# Ù¾ÙˆØ´Ù‡ Ø§Ø®Ø¨Ø§Ø± Ø±ÙˆØ²Ø§Ù†Ù‡
DAILY_NEWS_DIR = BASE / "daily_news"
DAILY_NEWS_DIR.mkdir(exist_ok=True)

# ================= HELPERS =================
def _ensure_file(path: Path, default):
    if not path.exists():
        with open(path, "w", encoding="utf-8") as f:
            json.dump(default, f, ensure_ascii=False, indent=2)

def _load_file(path: Path, default):
    _ensure_file(path, default)
    with open(path, encoding="utf-8") as f:
        return json.load(f)

def _save_file(path: Path, data):
    with open(path, "w", encoding="utf-8") as f:
        json.dump(data, f, ensure_ascii=False, indent=2)

# ================= SETTINGS =================
def get_setting(key, default=None):
    """ğŸ”§ FIX: Ø§ÙˆÙ„ Ø§Ø² ENV Ø¨Ø®ÙˆØ§Ù†ØŒ Ø¨Ø¹Ø¯ Ø§Ø² ÙØ§ÛŒÙ„"""
    # 1. Ú†Ú© Ú©Ø±Ø¯Ù† Environment Variable
    env_value = os.getenv(key)
    if env_value is not None:
        return env_value
    
    # 2. Ú†Ú© Ú©Ø±Ø¯Ù† ÙØ§ÛŒÙ„ ØªÙ†Ø¸ÛŒÙ…Ø§Øª
    data = _load_file(FILES["settings"], {})
    return data.get(key, default)

def set_setting(key, value):
    data = _load_file(FILES["settings"], {})
    data[key] = value
    _save_file(FILES["settings"], data)

# ================= SOURCES =================
def get_sources():
    return _load_file(FILES["sources"], {"rss": [], "scrape": []})

def get_rss_sources():
    return get_sources().get("rss", [])

def get_scrape_sources():
    return get_sources().get("scrape", [])

def add_rss_source(url):
    data = get_sources()
    if url not in data["rss"]:
        data["rss"].append(url)
        _save_file(FILES["sources"], data)

def add_scrape_source(url):
    data = get_sources()
    if url not in data["scrape"]:
        data["scrape"].append(url)
        _save_file(FILES["sources"], data)

def remove_rss_source(url):
    data = get_sources()
    if url in data["rss"]:
        data["rss"].remove(url)
        _save_file(FILES["sources"], data)

def remove_scrape_source(url):
    data = get_sources()
    if url in data["scrape"]:
        data["scrape"].remove(url)
        _save_file(FILES["sources"], data)

# ================= SENT (ØªÚ©Ø±Ø§Ø±ÛŒ Ù†Ø¨ÙˆØ¯Ù† Ø§Ø®Ø¨Ø§Ø±) =================
def is_sent(uid):
    """Ø¨Ø±Ø±Ø³ÛŒ Ø§ÛŒÙ†Ú©Ù‡ Ø®Ø¨Ø± Ù‚Ø¨Ù„Ø§Ù‹ Ø§Ø±Ø³Ø§Ù„ Ø´Ø¯Ù‡ ÛŒØ§ Ù†Ù‡"""
    try:
        data = _load_file(FILES["sent"], [])
        return str(uid) in [str(x) for x in data]
    except Exception as e:
        logger.error(f"Ø®Ø·Ø§ Ø¯Ø± is_sent: {e}")
        return False

def mark_sent(uid):
    """Ø¹Ù„Ø§Ù…Øªâ€ŒÚ¯Ø°Ø§Ø±ÛŒ Ø®Ø¨Ø± Ø¨Ù‡ Ø¹Ù†ÙˆØ§Ù† Ø§Ø±Ø³Ø§Ù„ Ø´Ø¯Ù‡"""
    try:
        data = _load_file(FILES["sent"], [])
        uid_str = str(uid)
        
        if uid_str not in [str(x) for x in data]:
            data.append(uid_str)
            
            # Ù†Ú¯Ù‡ Ø¯Ø§Ø´ØªÙ† ÙÙ‚Ø· 2000 Ø¢ÛŒØªÙ… Ø¢Ø®Ø±
            if len(data) > 2000:
                data = data[-2000:]
            
            _save_file(FILES["sent"], data)
            return True
        return False
    except Exception as e:
        logger.error(f"Ø®Ø·Ø§ Ø¯Ø± mark_sent: {e}")
        return False

# ================= COLLECTED NEWS =================
def save_collected_news(news_list):
    """Ø°Ø®ÛŒØ±Ù‡ Ø§Ø®Ø¨Ø§Ø± Ø¬Ù…Ø¹â€ŒØ¢ÙˆØ±ÛŒâ€ŒØ´Ø¯Ù‡ Ø¯Ø± ÙØ§ÛŒÙ„ Ø§ØµÙ„ÛŒ"""
    _save_file(FILES["news"], news_list)

def get_collected_news(limit=None):
    """Ø®ÙˆØ§Ù†Ø¯Ù† Ø§Ø®Ø¨Ø§Ø± Ø¬Ù…Ø¹â€ŒØ¢ÙˆØ±ÛŒâ€ŒØ´Ø¯Ù‡"""
    news = _load_file(FILES["news"], [])
    return news[:limit] if limit else news

# ================= DAILY NEWS (Ø¨Ø±Ø§ÛŒ ØªØ±Ù†Ø¯Ù‡Ø§) =================
def save_daily_news_item(news_item):
    """Ø°Ø®ÛŒØ±Ù‡ ÛŒÚ© Ø®Ø¨Ø± Ø¯Ø± ÙØ§ÛŒÙ„ Ø±ÙˆØ²Ø§Ù†Ù‡"""
    today = datetime.now().strftime("%Y-%m-%d")
    today_file = DAILY_NEWS_DIR / f"{today}.json"
    
    try:
        # Ø®ÙˆØ§Ù†Ø¯Ù† ÙØ§ÛŒÙ„ ÙØ¹Ù„ÛŒ
        if today_file.exists():
            with open(today_file, "r", encoding="utf-8") as f:
                content = json.load(f)
                news_list = content if isinstance(content, list) else []
        else:
            news_list = []
        
        # Ú†Ú© ØªÚ©Ø±Ø§Ø±ÛŒ Ù†Ø¨ÙˆØ¯Ù†
        url = news_item.get("link", news_item.get("url", ""))
        if url and any(n.get("url") == url for n in news_list):
            return
        
        # Ø§Ø¶Ø§ÙÙ‡ Ú©Ø±Ø¯Ù† Ø®Ø¨Ø± Ø¬Ø¯ÛŒØ¯
        news_list.append({
            "title": news_item.get("title", ""),
            "url": url,
            "source": news_item.get("source", "unknown"),
            "summary": news_item.get("summary", "")[:200],
            "timestamp": datetime.now().isoformat()
        })
        
        # Ø°Ø®ÛŒØ±Ù‡
        with open(today_file, "w", encoding="utf-8") as f:
            json.dump(news_list, f, ensure_ascii=False, indent=2)
        
    except Exception as e:
        logger.error(f"Ø®Ø·Ø§ Ø¯Ø± Ø°Ø®ÛŒØ±Ù‡ Ø®Ø¨Ø± Ø±ÙˆØ²Ø§Ù†Ù‡: {e}")

def get_daily_news(date=None):
    """Ø®ÙˆØ§Ù†Ø¯Ù† Ø§Ø®Ø¨Ø§Ø± ÛŒÚ© Ø±ÙˆØ² Ø®Ø§Øµ"""
    if date is None:
        date = datetime.now().strftime("%Y-%m-%d")
    
    today_file = DAILY_NEWS_DIR / f"{date}.json"
    
    if not today_file.exists():
        return []
    
    try:
        with open(today_file, "r", encoding="utf-8") as f:
            return json.load(f)
    except Exception as e:
        logger.error(f"Ø®Ø·Ø§ Ø¯Ø± Ø®ÙˆØ§Ù†Ø¯Ù† Ø§Ø®Ø¨Ø§Ø± Ø±ÙˆØ²Ø§Ù†Ù‡: {e}")
        return []

# ================= TOPICS / TRENDS =================
def save_topic(topic, url, source):
    """Ø°Ø®ÛŒØ±Ù‡ ÛŒÚ© ØªØ§Ù¾ÛŒÚ© Ø¨Ø±Ø§ÛŒ ØªØ­Ù„ÛŒÙ„ ØªØ±Ù†Ø¯"""
    data = _load_file(FILES["topics"], [])
    today = datetime.utcnow().date().isoformat()
    data.append({
        "topic": topic,
        "url": url,
        "source": source,
        "date": today
    })
    # Ù†Ú¯Ù‡ Ø¯Ø§Ø´ØªÙ† ÙÙ‚Ø· 30 Ø±ÙˆØ² Ø§Ø®ÛŒØ±
    cutoff = (datetime.utcnow().date() - timedelta(days=30)).isoformat()
    data = [item for item in data if item.get("date", "") >= cutoff]
    _save_file(FILES["topics"], data)

def daily_trends(min_sources=3):
    """Ù¾ÛŒØ¯Ø§ Ú©Ø±Ø¯Ù† ØªØ±Ù†Ø¯Ù‡Ø§ÛŒ Ø±ÙˆØ²Ø§Ù†Ù‡"""
    data = _load_file(FILES["topics"], [])
    today = datetime.utcnow().date().isoformat()
    count = {}

    for item in data:
        if item.get("date") == today:
            topic = item.get("topic", "")
            source = item.get("source", "")
            if topic:
                if topic not in count:
                    count[topic] = set()
                count[topic].add(source)

    # ÙÛŒÙ„ØªØ± ØªØ±Ù†Ø¯Ù‡Ø§ Ø¨Ø§ Ø­Ø¯Ø§Ù‚Ù„ ØªØ¹Ø¯Ø§Ø¯ Ù…Ù†Ø¨Ø¹
    trends = [topic for topic, sources in count.items() if len(sources) >= min_sources]
    return trends
