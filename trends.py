"""
Ù…Ø¯ÛŒØ±ÛŒØª Ùˆ ØªØ­Ù„ÛŒÙ„ ØªØ±Ù†Ø¯Ù‡Ø§ÛŒ Ø±ÙˆØ²Ø§Ù†Ù‡
"""

import json
import os
import re
from datetime import datetime
from collections import Counter
import jdatetime

TRENDS_FILE = "data/trends.json"


def _load_trends():
    """Ø¨Ø§Ø±Ú¯Ø°Ø§Ø±ÛŒ ØªØ±Ù†Ø¯Ù‡Ø§ Ø§Ø² ÙØ§ÛŒÙ„"""
    os.makedirs("data", exist_ok=True)
    if not os.path.exists(TRENDS_FILE):
        return []
    with open(TRENDS_FILE, "r", encoding="utf-8") as f:
        return json.load(f)


def _save_trends(trends):
    """Ø°Ø®ÛŒØ±Ù‡ ØªØ±Ù†Ø¯Ù‡Ø§"""
    os.makedirs("data", exist_ok=True)
    with open(TRENDS_FILE, "w", encoding="utf-8") as f:
        json.dump(trends, f, ensure_ascii=False, indent=2)


def normalize(title):
    """Ù†Ø±Ù…Ø§Ù„â€ŒØ³Ø§Ø²ÛŒ Ø¹Ù†ÙˆØ§Ù† Ø¨Ø±Ø§ÛŒ Ù…Ù‚Ø§ÛŒØ³Ù‡"""
    # Ø­Ø°Ù Ú©Ø§Ø±Ø§Ú©ØªØ±Ù‡Ø§ÛŒ Ø®Ø§Øµ
    title = re.sub(r'[^\w\s]', ' ', title.lower())
    # Ø­Ø°Ù ÙØ¶Ø§Ù‡Ø§ÛŒ Ø§Ø¶Ø§ÙÛŒ
    title = ' '.join(title.split())
    # ÙÙ‚Ø· 10 Ú©Ù„Ù…Ù‡ Ø§ÙˆÙ„
    words = title.split()[:10]
    return ' '.join(words)


def save_topic(title, link, source, date):
    """Ø°Ø®ÛŒØ±Ù‡ ÛŒÚ© Ù…ÙˆØ¶ÙˆØ¹/Ø®Ø¨Ø±"""
    trends = _load_trends()
    
    normalized_title = normalize(title)
    
    trends.append({
        "title": title,
        "normalized_title": normalized_title,
        "link": link,
        "source": source,
        "date": date
    })
    
    _save_trends(trends)


def get_daily_trends(date, min_sources=2):
    """
    Ø¯Ø±ÛŒØ§ÙØª ØªØ±Ù†Ø¯Ù‡Ø§ÛŒ ÛŒÚ© Ø±ÙˆØ² Ø®Ø§Øµ
    
    Args:
        date: ØªØ§Ø±ÛŒØ® Ø¨Ù‡ ÙØ±Ù…Øª ISO (YYYY-MM-DD)
        min_sources: Ø­Ø¯Ø§Ù‚Ù„ ØªØ¹Ø¯Ø§Ø¯ Ù…Ù†Ø§Ø¨Ø¹ Ø¨Ø±Ø§ÛŒ ØªØ¨Ø¯ÛŒÙ„ Ø¨Ù‡ ØªØ±Ù†Ø¯
    
    Returns:
        Ù„ÛŒØ³Øª ØªØ±Ù†Ø¯Ù‡Ø§ Ø¨Ø§ ØªØ¹Ø¯Ø§Ø¯ Ù…Ù†Ø§Ø¨Ø¹ Ùˆ Ù„ÛŒÙ†Ú©â€ŒÙ‡Ø§
    """
    trends = _load_trends()
    
    # ÙÛŒÙ„ØªØ± Ú©Ø±Ø¯Ù† ØªØ±Ù†Ø¯Ù‡Ø§ÛŒ Ø±ÙˆØ² Ù…ÙˆØ±Ø¯ Ù†Ø¸Ø±
    daily_items = [t for t in trends if t["date"] == date]
    
    if not daily_items:
        return []
    
    # Ú¯Ø±ÙˆÙ‡â€ŒØ¨Ù†Ø¯ÛŒ Ø¨Ø± Ø§Ø³Ø§Ø³ Ø¹Ù†ÙˆØ§Ù† Ù†Ø±Ù…Ø§Ù„ Ø´Ø¯Ù‡
    grouped = {}
    for item in daily_items:
        norm_title = item["normalized_title"]
        
        if norm_title not in grouped:
            grouped[norm_title] = {
                "title": item["title"],  # Ø¹Ù†ÙˆØ§Ù† Ø§ØµÙ„ÛŒ Ø§ÙˆÙ„ÛŒÙ† Ø®Ø¨Ø±
                "sources": set(),
                "links": []
            }
        
        grouped[norm_title]["sources"].add(item["source"])
        grouped[norm_title]["links"].append({
            "link": item["link"],
            "source": item["source"]
        })
    
    # ÙÛŒÙ„ØªØ± Ú©Ø±Ø¯Ù† ÙÙ‚Ø· Ù…ÙˆØ§Ø±Ø¯ Ø¨Ø§ Ø­Ø¯Ø§Ù‚Ù„ Ù…Ù†Ø¨Ø¹ Ù…ÙˆØ±Ø¯ Ù†ÛŒØ§Ø²
    result = []
    for norm_title, data in grouped.items():
        source_count = len(data["sources"])
        if source_count >= min_sources:
            result.append({
                "title": data["title"],
                "source_count": source_count,
                "links": data["links"][:3]  # ÙÙ‚Ø· 3 Ù„ÛŒÙ†Ú© Ø§ÙˆÙ„
            })
    
    # Ù…Ø±ØªØ¨â€ŒØ³Ø§Ø²ÛŒ Ø¨Ø± Ø§Ø³Ø§Ø³ ØªØ¹Ø¯Ø§Ø¯ Ù…Ù†Ø§Ø¨Ø¹ (Ø¨ÛŒØ´ØªØ±ÛŒÙ† Ø§ÙˆÙ„)
    result.sort(key=lambda x: x["source_count"], reverse=True)
    
    return result


def format_trend_message(date, min_sources=2):
    """
    Ø³Ø§Ø®Øª Ù¾ÛŒØ§Ù… ÙØ±Ù…Øª Ø´Ø¯Ù‡ ØªØ±Ù†Ø¯Ù‡Ø§ÛŒ Ø±ÙˆØ²
    
    Args:
        date: ØªØ§Ø±ÛŒØ® Ø¨Ù‡ ÙØ±Ù…Øª ISO
        min_sources: Ø­Ø¯Ø§Ù‚Ù„ Ù…Ù†Ø§Ø¨Ø¹
    
    Returns:
        Ù¾ÛŒØ§Ù… ÙØ±Ù…Øª Ø´Ø¯Ù‡ Ø¨Ø§ Markdown
    """
    trends = get_daily_trends(date, min_sources)
    
    if not trends:
        return None
    
    # ØªØ¨Ø¯ÛŒÙ„ ØªØ§Ø±ÛŒØ® Ø¨Ù‡ Ø´Ù…Ø³ÛŒ Ùˆ Ù…ÛŒÙ„Ø§Ø¯ÛŒ
    try:
        dt = datetime.fromisoformat(date)
        jdt = jdatetime.datetime.fromgregorian(datetime=dt)
        
        persian_date = jdt.strftime('%Y/%m/%d')
        gregorian_date = dt.strftime('%Y-%m-%d')
        
        day_name_fa = jdt.strftime('%A')  # Ù†Ø§Ù… Ø±ÙˆØ² ÙØ§Ø±Ø³ÛŒ
    except:
        persian_date = date
        gregorian_date = date
        day_name_fa = ""
    
    # Ø³Ø§Ø®Øª Ù¾ÛŒØ§Ù…
    msg = "ğŸ“Š *ØªØ±Ù†Ø¯Ù‡Ø§ÛŒ Ø±ÙˆØ² Ø³ÛŒÙ†Ù…Ø§*\n\n"
    msg += f"ğŸ“… {day_name_fa} {persian_date}\n"
    msg += f"ğŸ“† Ù…ÛŒÙ„Ø§Ø¯ÛŒ: {gregorian_date}\n\n"
    msg += f"ğŸ”¥ *Ø¯Ø§Øºâ€ŒØªØ±ÛŒÙ† Ø§Ø®Ø¨Ø§Ø± Ø±ÙˆØ²* (Ø­Ø¯Ø§Ù‚Ù„ {min_sources} Ù…Ù†Ø¨Ø¹):\n\n"
    
    for i, trend in enumerate(trends[:10], 1):  # ÙÙ‚Ø· 10 ØªØ±Ù†Ø¯ Ø§ÙˆÙ„
        title = trend["title"][:100]  # Ù…Ø­Ø¯ÙˆØ¯ Ú©Ø±Ø¯Ù† Ø·ÙˆÙ„ Ø¹Ù†ÙˆØ§Ù†
        count = trend["source_count"]
        first_link = trend["links"][0]["link"] if trend["links"] else "#"
        
        msg += f"{i}. [{title}]({first_link})\n"
        msg += f"   ğŸ“° {count} Ù…Ù†Ø¨Ø¹\n\n"
    
    msg += f"_âœ… Ù…Ø¬Ù…ÙˆØ¹ {len(trends)} ØªØ±Ù†Ø¯ ÛŒØ§ÙØª Ø´Ø¯_"
    
    return msg


def clear_old_trends(days=7):
    """Ø­Ø°Ù ØªØ±Ù†Ø¯Ù‡Ø§ÛŒ Ù‚Ø¯ÛŒÙ…ÛŒâ€ŒØªØ± Ø§Ø² N Ø±ÙˆØ²"""
    trends = _load_trends()
    today = datetime.now().date()
    
    filtered = []
    for t in trends:
        try:
            trend_date = datetime.fromisoformat(t["date"]).date()
            age = (today - trend_date).days
            if age <= days:
                filtered.append(t)
        except:
            # Ø§Ú¯Ø± ØªØ§Ø±ÛŒØ® Ù…Ø¹ØªØ¨Ø± Ù†Ø¨ÙˆØ¯ØŒ Ù†Ú¯Ù‡ Ø¯Ø§Ø±
            filtered.append(t)
    
    _save_trends(filtered)
    return len(trends) - len(filtered)


if __name__ == "__main__":
    # ØªØ³Øª
    print("ğŸ§ª ØªØ³Øª Ø³ÛŒØ³ØªÙ… ØªØ±Ù†Ø¯Ù‡Ø§...\n")
    
    # ØªØ³Øª Ø°Ø®ÛŒØ±Ù‡
    today = datetime.now().date().isoformat()
    save_topic("Breaking: New Marvel Movie Announced", "http://example.com/1", "source1", today)
    save_topic("Marvel announces new blockbuster film", "http://example.com/2", "source2", today)
    save_topic("Exciting Marvel News: New Film Coming", "http://example.com/3", "source3", today)
    
    # ØªØ³Øª Ø¯Ø±ÛŒØ§ÙØª
    trends = get_daily_trends(today, min_sources=2)
    print(f"âœ… {len(trends)} ØªØ±Ù†Ø¯ ÛŒØ§ÙØª Ø´Ø¯\n")
    
    # ØªØ³Øª ÙØ±Ù…Øª
    msg = format_trend_message(today, min_sources=2)
    if msg:
        print(msg)
    else:
        print("âŒ ØªØ±Ù†Ø¯ÛŒ ÛŒØ§ÙØª Ù†Ø´Ø¯")
